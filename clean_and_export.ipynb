{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from US_Accidents_March23_1_percent.csv, clean it and import to new csv file.  \n",
    "Making one file where all NaN numbers are deleted: US_Accidents_March23_1_percent_cleaned.csv  \n",
    "Making another file where all NaN numbers converted to 0: One_Percent_Null_To_Zero.csv   \n",
    "We can use US_Accidents_March23_1_percent_cleaned.csv for our graphs and One_Percent_Null_To_Zero.csv if we want all data.  \n",
    "Most of the NaN values were found in latitude and longitude cells, so it's OK if we delete whose records.\n",
    "\n",
    "# Imports Licenesed_drivers_By_State.csv, clean it and make df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the csv Licenesed_drivers_By_State.csv file and make a data frame\n",
    "Drivers_path = Path(\"data/Licensed_drivers_By_State.csv\")\n",
    "Drivers_df = pd.read_csv(Drivers_path)\n",
    "Drivers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping all states for converting full names to abbriviations.\n",
    "#We need this so state names in both CSV files have the same column States\n",
    "state_mapping = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa',\n",
    "    'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
    "    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island', 'SC': 'South Carolina', 'SD': 'South Dakota', 'TN': 'Tennessee',\n",
    "    'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington',\n",
    "    'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "reverse_state_mapping = {\n",
    "    value: key\n",
    "    for key, value in state_mapping.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting state full name to abbreviation\n",
    "Drivers_df['State'] = Drivers_df['State'].map(reverse_state_mapping)\n",
    "Drivers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'State' and 'Year', then calculate the total number of drivers\n",
    "state_population = Drivers_df.groupby(['State', 'Year'])['Drivers'].sum().reset_index()\n",
    "\n",
    "# Rename the column for clarity (optional)\n",
    "state_population.rename(columns={'Drivers': 'Total_Drivers'}, inplace=True)\n",
    "\n",
    "state_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out all years exept 2016-2023 to match with accidents data\n",
    "Drivers_filtered = Drivers_df[(Drivers_df['Year'] >= 2016) & (Drivers_df['Year'] <= 2023)]\n",
    "Drivers_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drivers_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing only 2018 drivers. There are several age groups in every state.\n",
    "Drivers_2018 = Drivers_df[Drivers_df['Year'] == 2018]\n",
    "Drivers_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating number of drivers per state\n",
    "#Using only 2018 data as it's the one more complete.\n",
    "#Assuming rough driver count is the same year by year. We need this data to calculate accidents per population.\n",
    "Drivers_by_State = Drivers_2018.groupby('State')['Drivers'].sum().reset_index()\n",
    "Drivers_by_State.columns = ['State', 'Drivers']\n",
    "\n",
    "Drivers_by_State.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To csv file\n",
    "#Use this data for SQL\n",
    "Drivers_by_State.to_csv('data/Licensed_Drivers_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on Accidents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the csv file and make a data frame\n",
    "US_Accidents_path = Path(\"data/US_Accidents_March23_1_percent.csv\")\n",
    "US_Accidents_df = pd.read_csv(US_Accidents_path)\n",
    "US_Accidents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new JSON file for US_Accidents_March23_1_percent\n",
    "# Load the CSV file\n",
    "csv_file_path = 'data/US_Accidents_March23_1_percent.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert to JSON\n",
    "json_file_path = 'data/US_Accidents_March23_1_percent_JSON.json'\n",
    "df.to_json(json_file_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all columns\n",
    "US_Accidents_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting columns that we don't need\n",
    "#Columns to delete:\n",
    "#<!-- Source, End_Lat, End_Lng, Distance(mi), Country, Weather_Timestamp, Civil_Twilight, Nautical_Twilight, Astronomical_Twilight -->\n",
    "US_Accidents_df_copy = US_Accidents_df.copy()\n",
    "\n",
    "columns_to_delete = [\n",
    "    'Source', 'End_Lat', 'End_Lng', 'Distance(mi)', \n",
    "    'Country', 'Weather_Timestamp', 'Civil_Twilight',\n",
    "     'Nautical_Twilight', 'Astronomical_Twilight'\n",
    "]\n",
    "\n",
    "US_Accidents_df_copy = US_Accidents_df_copy.drop(columns=columns_to_delete)\n",
    "US_Accidents_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all NaN data\n",
    "US_Accidents_cleaned = US_Accidents_df_copy.dropna()\n",
    "US_Accidents_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_Accidents_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new csv file for cleaned data\n",
    "US_Accidents_cleaned.to_csv(\"data/US_Accidents_March23_1_percent_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new JSON file for cleaned data\n",
    "# Load the CSV file\n",
    "csv_file_path = 'data/US_Accidents_March23_1_percent_cleaned.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert to JSON\n",
    "json_file_path = 'data/US_Accidents_March23_1_percent_cleaned.json'\n",
    "df.to_json(json_file_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making new data with all NaN converted to 0. When we delete all NaN we delete the whole row. \n",
    "# Making data with these rows but NaN converted to 0.\n",
    "US_Accidents_Null_To_Zero = US_Accidents_df_copy.copy()\n",
    "US_Accidents_Null_To_Zero = US_Accidents_Null_To_Zero.fillna(0)\n",
    "US_Accidents_Null_To_Zero.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_Accidents_Null_To_Zero.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new csv file for cleaned data\n",
    "US_Accidents_Null_To_Zero.to_csv(\"data/One_Percent_Null_To_Zero.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new JSON file for cleaned data\n",
    "# Load the CSV file\n",
    "csv_file_path = 'data/One_percent_Null_To_Zero.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert to JSON\n",
    "json_file_path = 'data/One_percent_Null_To_Zero_JSON.json'\n",
    "df.to_json(json_file_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make 2 columns at the end: Date and Year. Convert Start_Time to datetime format\n",
    "accidents_df = pd.read_csv(\"data/One_Percent_Null_To_Zero.csv\")\n",
    "accidents_df['Date'] =  pd.to_datetime(accidents_df['Start_Time'], format ='mixed')\n",
    "accidents_df['Year'] = accidents_df.Date.dt.year\n",
    "\n",
    "print(accidents_df.columns)\n",
    "accidents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this data for SQL.\n",
    "accidents_df.to_csv('data/Accidents.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
